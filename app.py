import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import tempfile

def show_theory():
    st.header("1. Ph∆∞∆°ng ph√°p ph√°t hi·ªán v√† l√†m m·ªù khu√¥n m·∫∑t")
    
    st.subheader("1.1. Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng Haar Cascade")
    st.write("""
    Haar Cascade l√† m·ªôt ph∆∞∆°ng ph√°p h·ªçc m√°y ƒë·ªÉ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Paul Viola v√† Michael Jones. 
    Ph∆∞∆°ng ph√°p n√†y s·ª≠ d·ª•ng c√°c ƒë·∫∑c tr∆∞ng Haar ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t trong h√¨nh ·∫£nh:
    
    C√≥ th·ªÉ minh h·ªça qu√° tr√¨nh ph√°t hi·ªán g∆∞∆°ng m·∫∑t nh∆∞ sau :

    - (1) ·∫¢nh d·∫ßu v√†o ƒë∆∞·ª£c chia th√†nh nhi·ªÅu c·ª≠a s·ªï nh·ªè (subwindows) ƒë·ªÉ qu√©t to√†n b·ªô h√¨nh ·∫£nh.
    - (2) C√°c c·ª≠a s·ªï n√†y s·∫Ω ƒë∆∞·ª£c duy·ªát tu·∫ßn t·ª± ƒë·ªÉ ki·ªÉm tra s·ª± hi·ªán di·ªán c·ªßa khu√¥n m·∫∑t.
    - (3) V·ªõi t·ª´ng c·ª≠a s·ªï con, ƒë·∫∑c tr∆∞ng quan tr·ªçng s·∫Ω ƒë∆∞·ª£c tr√≠ch xu·∫•t.
    - (4) Sau ƒë√≥, c√°c ƒë·∫∑c tr∆∞ng c·ªßa t·ª´ng c·ª≠a s·ªï con ƒë∆∞·ª£c so s√°nh v·ªõi vector ƒë·∫∑c tr∆∞ng c·ªßa t·∫≠p hu·∫•n luy·ªán.
    - (5) S·ª≠ d·ª•ng c∆° ch·∫ø c∆° ch·∫ø "Cascade of Classifiers" (Ph√¢n lo·∫°i theo t·∫ßng) ƒë·ªÉ ph√°t hi·ªán g∆∞∆°ng m·∫∑t.
    - (6) N·∫øu c·ª≠a s·ªï con ƒë∆∞·ª£c x√°c ƒë·ªãnh l√† g∆∞∆°ng m·∫∑t, th√¨ s·∫Ω ƒë∆∞·ª£c ph√¢n lo·∫°i l√† g∆∞∆°ng m·∫∑t, c√≤n kh√¥ng th√¨ ng∆∞·ª£c l·∫°i.
    """)

    col1 , col2 , col3 = st.columns([1,10,1])
    with col2:
        st.image("·∫¢nh G·ªëc.jpg", caption="Minh h·ªça qu√° tr√¨nh phat hi·ªán khu√¥n m·∫∑t b·∫±ng Haar Cascade")

    st.subheader("1.2. L√†m m·ªù khu√¥n m·∫∑t b·∫±ng Gaussian Blur")
    st.write("""
    Gaussian Blur l√† m·ªôt k·ªπ thu·∫≠t l√†m m·ªù h√¨nh ·∫£nh d·ª±a tr√™n ph√¢n ph·ªëi Gaussian:

    1. **Nguy√™n l√Ω ho·∫°t ƒë·ªông**:
    - S·ª≠ d·ª•ng ma tr·∫≠n kernel c√≥ tr·ªçng s·ªë theo ph√¢n ph·ªëi Gaussian 2D
    - M·ªói pixel m·ªõi l√† trung b√¨nh c√≥ tr·ªçng s·ªë c·ªßa c√°c pixel l√¢n c·∫≠n
    - Tr·ªçng s·ªë gi·∫£m d·∫ßn theo kho·∫£ng c√°ch t·ª´ pixel trung t√¢m

    2. **Tham s·ªë quan tr·ªçng**:
    - K√≠ch th∆∞·ªõc kernel: Quy·∫øt ƒë·ªãnh m·ª©c ƒë·ªô l√†m m·ªù
    - ƒê·ªô l·ªách chu·∫©n (œÉ): Ki·ªÉm so√°t h√¨nh d·∫°ng c·ªßa ph√¢n ph·ªëi Gaussian

    3. **∆Øu ƒëi·ªÉm**:
    - L√†m m·ªù t·ª± nhi√™n, m∆∞·ª£t m√†
    - Gi·∫£m nhi·ªÖu hi·ªáu qu·∫£
    - B·∫£o to√†n c√°c c·∫°nh t·ªët h∆°n so v·ªõi l√†m m·ªù trung b√¨nh

    4. **√Åp d·ª•ng trong ·ª©ng d·ª•ng**:
    - Kernel size t·ª∑ l·ªá v·ªõi k√≠ch th∆∞·ªõc khu√¥n m·∫∑t
    - S·ª≠ d·ª•ng m·∫∑t n·∫° h√¨nh elip ƒë·ªÉ t·∫°o hi·ªáu ·ª©ng t·ª± nhi√™n
    - L√†m m·ªãn vi·ªÅn ƒë·ªÉ tr√°nh hi·ªán t∆∞·ª£ng rƒÉng c∆∞a
    """)

    # Th√™m hai c·ªôt ƒë·ªÉ hi·ªÉn th·ªã h√¨nh ·∫£nh v√† gif minh h·ªça
    col1, col2 = st.columns(2)
    
    with col1:
        st.image("gaussian_kernel_3d.png", caption="·∫¢nh g·ªëc")
    
    with col2:
        st.image("gaussian_blur_demo.png", caption="Minh h·ªça qu√° tr√¨nh √°p d·ª•ng Gaussian Blur v·ªõi 1 ph·∫ßn nh·ªè")

    st.markdown("Minh h·ªça")

    col1, col2 = st.columns(2)
    
    with col1:
        st.image("cat.jpg", caption="Minh h·ªça qu√° tr√¨nh √°p d·ª•ng Gaussian Blur v·ªõi 1 ph·∫ßn nghi·ªám")
    
    with col2:
        st.image("blur-demo.gif", caption="Minh h·ªça qu√° tr√¨nh √°p d·ª•ng Gaussian Blur v·ªõi 1 ph·∫ßn l·ªõn")

   
def show_application():
    st.write("T·∫£i l√™n ·∫£nh ho·∫∑c video ƒë·ªÉ ph√°t hi·ªán v√† l√†m m·ªù khu√¥n m·∫∑t.")
    
    # T·∫°o container cho ph·∫ßn ƒëi·ªÅu khi·ªÉn
    with st.container():
        col1, col2 = st.columns([2, 1])
        
        with col1:
            blur_strength = st.slider(
                "ƒêi·ªÅu ch·ªânh ƒë·ªô m·ªù",
                min_value=1,
                max_value=100,
                value=50,
                help="K√©o thanh tr∆∞·ª£t ƒë·ªÉ ƒëi·ªÅu ch·ªânh ƒë·ªô m·ªù (1: m·ªù nh·∫π, 100: m·ªù t·ªëi ƒëa)"
            )
        
        with col2:
            mode = st.radio("Ch·ªçn ch·∫ø ƒë·ªô:", ["·∫¢nh", "Video"])
    
    # Container cho ph·∫ßn upload v√† hi·ªÉn th·ªã
    with st.container():
        if mode == "·∫¢nh":
            uploaded_file = st.file_uploader(
                "Ch·ªçn ·∫£nh...", 
                type=['jpg', 'jpeg', 'png'],
                help="K√©o th·∫£ ho·∫∑c ch·ªçn file ·∫£nh t·ª´ m√°y t√≠nh"
            )
            
            if uploaded_file is not None:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("·∫¢nh g·ªëc")
                    image = Image.open(uploaded_file)
                    st.image(image, use_column_width=True)
                    if st.button('Ph√°t hi·ªán v√† l√†m m·ªù khu√¥n m·∫∑t'):
                        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                        processed_image = blur_face(image, face_cascade, blur_strength)
                        processed_image = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)
                        
                        with col2:
                            st.subheader("·∫¢nh sau khi x·ª≠ l√Ω")
                            st.image(processed_image, use_column_width=True)
                            
                            is_success, buffer = cv2.imencode(".png", cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR))
                            io_buf = io.BytesIO(buffer)
                            
                            st.download_button(
                                label="T·∫£i ·∫£nh ƒë√£ x·ª≠ l√Ω",
                                data=io_buf.getvalue(),
                                file_name="blurred_face.png",
                                mime="image/png"
                            )
        else:
            uploaded_file = st.file_uploader(
                "Ch·ªçn video...", 
                type=['mp4', 'avi', 'mov'],
                help="K√©o th·∫£ ho·∫∑c ch·ªçn file video t·ª´ m√°y t√≠nh"
            )
            
            if uploaded_file is not None:
                tfile = tempfile.NamedTemporaryFile(delete=False)
                tfile.write(uploaded_file.read())
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Video g·ªëc")
                    st.video(uploaded_file)
                    if st.button('Ph√°t hi·ªán v√† l√†m m·ªù khu√¥n m·∫∑t'):
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        with st.spinner('ƒêang x·ª≠ l√Ω video...'):
                            output_video = process_video(tfile.name, blur_strength, progress_bar)
                            
                        progress_bar.empty()
                        status_text.empty()
                        
                        with col2:
                            st.subheader("Video sau khi x·ª≠ l√Ω")
                            st.video(output_video)
                            
                            with open(output_video, 'rb') as f:
                                video_bytes = f.read()
                                st.download_button(
                                    label="T·∫£i video ƒë√£ x·ª≠ l√Ω",
                                    data=video_bytes,
                                    file_name="blurred_face.mp4",
                                    mime="video/mp4"
                                )

def create_elliptical_mask(height, width):
    mask = np.zeros((height, width), dtype=np.uint8)
    center = (width // 2, height // 2)
    axes = (width // 2, height // 2)
    cv2.ellipse(mask, center, axes, 0, 0, 360, 255, -1)
    mask = cv2.GaussianBlur(mask, (19, 19), 0)
    return mask

def blur_face(image, face_cascade, blur_strength):
    if isinstance(image, Image.Image):
        image = np.array(image.convert('RGB'))
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(
        gray,
        scaleFactor=1.1,
        minNeighbors=5,
        minSize=(30, 30),
        flags=cv2.CASCADE_SCALE_IMAGE
    )
    
    for (x, y, w, h) in faces:
        padding = int(min(w, h) * 0.1)
        x1 = max(x - padding, 0)
        y1 = max(y - padding, 0)
        x2 = min(x + w + padding, image.shape[1])
        y2 = min(y + h + padding, image.shape[0])
        
        face_region = image[y1:y2, x1:x2]
        
        base_kernel = int((blur_strength / 100.0) * min(w, h))
        kernel_size = max(base_kernel, 3)
        kernel_size = kernel_size if kernel_size % 2 == 1 else kernel_size + 1
        
        blurred_face = cv2.GaussianBlur(face_region, (kernel_size, kernel_size), 0)
        
        mask = create_elliptical_mask(y2-y1, x2-x1)
        mask = cv2.GaussianBlur(mask, (9, 9), 0)
        mask_3channel = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR) / 255.0
        
        face_region_new = face_region * (1 - mask_3channel) + blurred_face * mask_3channel
        image[y1:y2, x1:x2] = face_region_new
    
    return image

def process_video(video_path, blur_strength, progress_bar):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("Cannot open video file")
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    temp_output = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
    fourcc = cv2.VideoWriter_fourcc(*'avc1')
    out = cv2.VideoWriter(temp_output, fourcc, fps, (width, height))
    
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
            
        frame_processed = blur_face(frame, face_cascade, blur_strength)
        out.write(frame_processed)
        
        frame_count += 1
        if frame_count % 10 == 0:
            progress = frame_count / total_frames
            progress_bar.progress(progress, f"Processing: {frame_count}/{total_frames} frames")
    
    cap.release()
    out.release()
    
    return temp_output

def main():
    st.set_page_config(
        page_title="·ª®ng d·ª•ng l√†m m·ªù khu√¥n m·∫∑t trong h√¨nh ·∫£nh ho·∫∑c video gi√°m s√°t",
        page_icon="üë§",
        layout="centered",
        initial_sidebar_state="collapsed"
    )
    
    # CSS ƒë·ªÉ t√πy ch·ªânh giao di·ªán
    st.markdown("""
        <style>
        .main {
            padding: 0rem 1rem;
        }
        .stTabs [data-baseweb="tab-list"] {
            gap: 2px;
        }
        .stTabs [data-baseweb="tab"] {
            padding: 10px 20px;
        }
        .block-container {
            padding-top: 2rem;
            padding-bottom: 2rem;
            padding-left: 2rem;
            padding-right: 2rem;
        }
        h1 {
            text-align: center;
            padding-bottom: 2rem;
        }
        </style>
    """, unsafe_allow_html=True)
    
    with st.container():
        st.title("·ª®ng d·ª•ng Ph√°t hi·ªán v√† L√†m m·ªù Khu√¥n m·∫∑t")
        
        # T·∫°o tabs
        tab1, tab2 = st.tabs(["L√Ω thuy·∫øt", "·ª®ng d·ª•ng"])
        
        with tab1:
            show_theory()
        
        with tab2:
            show_application()

if __name__ == "__main__":
    main()
